<!DOCTYPE html>
<html>
  <head>
    <meta charset="UTF-8">
    <title>Kaining Ying | IIAU</title>
  </head>
  <body>
    <h1>Kaining Ying</h1>
    <figcaption>拍摄于VALSE无锡</figcaption>
    <img src="assets/wuxi2023.jpg" alt="Example Image" width="800" height="600">
    <p>CS Master@ZJUT supervised by <a href="https://cie.nwsuaf.edu.cn/szdw/fjs/2022110082/index.htm">Prof. Zhenhua Wang</a>. </p>
    <p>Email: <b>kaining[dot]ying[dot]cv[at]gmail[dot]com</b></p>
    <p><a href="https://scholar.google.com/citations?user=MDvaeqUAAAAJ&hl=zh-CN">Google Scholar</a> | <a href="https://github.com/KainingYing">GitHub</a></p>
    
    <h2>Research Interests</h2>
    <ul>
      <li><b>Multimodal-LLMs</b></li>
      <li><b>Segment Anything</b></li>
      <li>Object Detection & Instance Segmentation</li>
      <li>Human-centric Interaction Understanding</li>
    </ul>
    
    <h2>Education</h2>
    <ul>
      <li><b>IIAU-LAB@Dalian University of Technology</b>, Upcoming PhD Candidate (supervised by <a href="https://ice.dlut.edu.cn/IIAU/en/welcome-to-our-iiau-lab-english/index.html">Prof. Huchuan Lu</a>), 2024~2028</li>
      <li><b>CAD&CG@Zhejiang University</b>, Visiting Student (supervised by <a href="https://cshen.github.io/">Prof. Chunhua Shen</a> and <a href="https://stan-haochen.github.io/">Prof. Hao Chen</a>), 2022.7~Present</li>
      <li><b>CS@Zhejiang University of Technology</b>, Master (supervised by <a href="https://cie.nwsuaf.edu.cn/szdw/fjs/2022110082/index.htm">Prof. Zhenhua Wang</a>, 2021.7~Present</li>
    </ul>
    
    <h2>Publications</h2>
    <font size="3">* indicates equal contributions, # indicates corresponding authors</font>
    <br>
    <b><font size="4">CTVIS: Consistent Training for Online Video Instance Segmentation</font></b>
    <br>
    <b>Kaining Ying*</b>, Qing Zhong*, Weian Mao, Zhenhua Wang#, Hao Chen#, Lin Yuanbo Wu, Yifan Liu, Chenxiang Fan, Yunzhi Zhuge, Chunhua Shen. <span style="color:orange"><b>ICCV 2023</b></span>
    <br>
    <a href="https://arxiv.org/abs/2307.12616">PAPER</a>
    <a href="https://github.com/KainingYing/CTVIS">CODE</a>
    <a href="https://www.bilibili.com/video/BV1Y54y1K7kJ/?spm_id_from=333.999.0.0">DEMO</a>
    <br>
    <br>

    <b><font size="4">ISDA: Position-Aware Instance Segmentation with Deformable Attention</font></b>
    <br>
    <b>Kaining Ying</b>, Zhenhua Wang#, Cong Bai, Pengfei Zhou. <span style="color:orange"><b>ICASSP 2022 Oral</b></span>
    <br>
    <a href="https://arxiv.org/abs/2202.12251">PAPER</a> |
    <a href="https://github.com/KainingYing/ISDA">CODE</a> |
    <a href="https://www.bilibili.com/video/BV1RT4y1Y7qW/?spm_id_from=333.999.0.0">VIDEO</a>
    <br>
    <br>

    <b><font size="4">Human-to-Human Interaction Detection</font></b>
    <br>
    Zhenhua Wang, <b>Kaining Ying#</b>, Jiajun Meng, Jifeng Ning, Cong Bai. <span style="color:orange"><b>Preprint 2023</b></span>
    <br>
    <a href="https://arxiv.org/abs/2307.00464">PAPER</a>
    <br>
    <br>

    <b><font size="4">Self-supervised Enhancement for Named Entity Disambiguation via Multimodal Graph Convolution</font></b>
    <br>
    Pengfei Zhou*, <b>Kaining Ying*</b>, Zhenhua Wang, Dongyan Guo, Cong Bai#. <span style="color:orange"><b>TNNLS 2022</b></span>
    <br>
    <a href="https://ieeexplore.ieee.org/document/9774860/">PAPER</a> |
    <a href="https://github.com/LanceZPF/NNED_MMGraph">CODE</a>
    <br>
    <br>

    <b><font size="4">Human Interaction Understanding with Consistency-Aware Learning</font></b>
    <br>
    Jiajun Meng, Zhenhua Wang#, <b>Kaining Ying</b>, Jianhua Zhang, Dongyan Guo, Zhen Zhang, Qinfeng Shi, Shengyong Chen. <span style="color:orange"><b>TPAMI 2023</b></span>
    <br>
    <a href="https://ieeexplore.ieee.org/document/10138446/">PAPER</a> |
    <a href="https://github.com/deepgogogo/CAGNet">CODE</a>
    <br>
    <br>
    
    <h2>Professional Service</h2>
    <p>Reviewer of TMM, ICME 2023 and ACM MM 2023.</p>
    
    <h2>Honors and Awards</h2>
    <ul>
      <li> 2nd Place in The 5th Large-scale Video Object Segmentation Challenge - Track 2: Video Instance Segmentation at ICCV 2023, 2023.8</li>
      <li> <a href="assets/cvpr_vps_2nd.pdf">2nd Place in Pixel-level Video Understanding Challenge (VPS Track) at CVPR2023, 2023.5</a></li>
      <li> China National Scholarship 2022 (1/306), 2022.10</li>
    </ul>

    
  </body>
</html>
